================================================================================
DOCUMENTACION COMPLETA DEL PROYECTO
RECONOCIMIENTO DE EMOCIONES FACIALES CON CNN
================================================================================

Materia: Redes Neuronales y Aprendizaje Profundo
Fecha de documentacion: Enero 2026

================================================================================
TABLA DE CONTENIDOS
================================================================================
1. Descripcion General del Proyecto
2. Estado Inicial del Proyecto
3. Cronologia Completa de Decisiones
4. Enfoques que NO Funcionaron
5. Enfoques que SI Funcionaron
6. Referencias y Fuentes
7. Estado Final del Proyecto
8. Conclusiones y Lecciones Aprendidas

================================================================================
1. DESCRIPCION GENERAL DEL PROYECTO
================================================================================

Objetivo: Desarrollar un sistema de reconocimiento de emociones faciales en
tiempo real utilizando redes neuronales convolucionales (CNN).

Clases de emociones (8 categorias):
- ira (anger)
- desprecio (contempt)
- asco (disgust)
- miedo (fear)
- felicidad (happiness)
- neutralidad (neutral)
- tristeza (sadness)
- sorpresa (surprise)

Datasets utilizados:
- FER2013 (Kaggle): Dataset principal con expresiones actuadas
- AffectNet (Kaggle): Dataset complementario
- RAF-DB: Dataset con expresiones reales (agregado posteriormente)
- CK+ (Cohn-Kanade): Dataset con expresiones reales (agregado posteriormente)

Archivos principales del proyecto:
- train.py: Script de entrenamiento
- test.py: Script de evaluacion
- camera.py: Deteccion en tiempo real via webcam
- requirements.txt: Dependencias del proyecto

================================================================================
2. ESTADO INICIAL DEL PROYECTO
================================================================================

El proyecto inicio con una arquitectura CNN basica:
- 4 bloques convolucionales: 32 -> 64 -> 128 -> 256 filtros
- Imagenes de entrada: 96x96 pixeles en escala de grises
- Preprocesamiento: CLAHE para mejora de contraste + normalizacion [0,1]

Resultados iniciales:
- Precision global: ~65% en test
- Problemas severos en clases minoritarias:
  * asco: ~33%
  * miedo: ~35%
  * ira: ~44%
  * sorpresa: ~45%
- Clases fuertes:
  * felicidad: ~92%
  * neutralidad: ~93%
  * tristeza: ~90%

Problemas identificados:
1. Desbalance de clases severo en el dataset
2. Baja precision en emociones "sutiles" (asco, miedo)
3. requirements.txt tenia paquetes de Ubuntu en lugar de dependencias Python

================================================================================
3. CRONOLOGIA COMPLETA DE DECISIONES
================================================================================

------------------------------------------------------------------------------
FASE 1: MEJORAS INICIALES AL MODELO BASE
------------------------------------------------------------------------------

DECISION 1.1: Corregir requirements.txt
- Problema: Contenia paquetes de sistema Ubuntu, no dependencias Python
- Solucion: Reescribir con dependencias correctas (torch, torchvision,
  opencv-python, numpy, scikit-learn, matplotlib, seaborn)
- Resultado: Instalacion correcta del entorno

DECISION 1.2: Implementar Class Weights (Pesos de Clase)
- Problema: Desbalance severo entre clases
- Justificacion: Las clases minoritarias (asco, desprecio) tenian menos
  ejemplos, causando que el modelo las ignorara
- Implementacion: Pesos inversamente proporcionales a la frecuencia de clase
- Formula: peso_clase = total_muestras / (num_clases * muestras_clase)
- Resultado: Mejora de +3-5% en clases minoritarias

DECISION 1.3: Agregar Data Augmentation
- Problema: Modelo sobreajustado a datos de entrenamiento
- Tecnicas implementadas:
  * Flip horizontal aleatorio (p=0.5)
  * Rotacion aleatoria (+/- 15 grados)
  * Ajuste de brillo aleatorio
- Justificacion: Aumenta variabilidad sin necesitar mas datos
- Resultado: Mejora en generalizacion

DECISION 1.4: Mejorar arquitectura CNN (2 conv layers por bloque)
- Problema: Arquitectura muy simple para problema complejo
- Cambio: De 1 capa conv por bloque a 2 capas conv por bloque
- Patron: Conv -> BatchNorm -> ReLU -> Conv -> BatchNorm -> ReLU -> MaxPool -> Dropout
- Resultado: Mejor extraccion de caracteristicas

DECISION 1.5: Ajustar hiperparametros
- Learning rate: Reducido a 0.0005 (de 0.001)
- Early stopping patience: Aumentado a 15 epocas
- Justificacion: Entrenamiento mas estable, evitar detener prematuramente

RESULTADO FASE 1: 69.7% precision global (+4.7% vs baseline)
- asco: +15% (de 33% a ~48%)
- miedo: +17% (de 35% a ~52%)

------------------------------------------------------------------------------
FASE 2: INTENTO DE TRANSFER LEARNING (FALLIDO)
------------------------------------------------------------------------------

DECISION 2.1: Implementar ResNet-18 preentrenado
- Hipotesis: Transfer learning con ImageNet mejoraria resultados
- Implementacion:
  * Cargar ResNet-18 con pesos de ImageNet
  * Modificar primera capa para escala de grises (1 canal)
  * Modificar ultima capa para 8 clases

PROBLEMA 2.1: Overfitting severo
- Resultado: Train 99% vs Val 68%
- Causa: Domain mismatch entre ImageNet (objetos) y caras/emociones

DECISION 2.2: Cambiar a imagenes RGB
- Descubrimiento: El dataset original estaba en color, no escala de grises
- Cambio: Mantener 3 canales RGB
- Normalizacion ImageNet: mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]

PROBLEMA 2.2: Error de memoria
- Error: RAM overflow (9GB necesarios para 224x224 RGB)
- Solucion 1: Reducir a float32 - aun insuficiente
- Solucion 2: Reducir imagenes a 128x128 - funciono pero resultados pobres

DECISION 2.3: Implementar tecnicas avanzadas de regularizacion
- Focal Loss: Para enfocarse en ejemplos dificiles
- Weighted Random Sampler: Balancear exposicion de clases
- Carga on-demand: Resolver problema de RAM
- TTA (Test-Time Augmentation): Flip + promedio
- Augmentation agresiva para clases minoritarias
- Progressive unfreezing: Descongelar capas gradualmente

RESULTADO FASE 2: 68.93% validacion, ~68.5% test
- PEOR que CNN custom (69.7%)
- Conclusion: Transfer learning no viable para este dominio

DECISION CLAVE: Abandonar Transfer Learning, volver a CNN custom

------------------------------------------------------------------------------
FASE 3: OPTIMIZACION DE CNN CUSTOM
------------------------------------------------------------------------------

DECISION 3.1: Aumentar capacidad del modelo
- Cambio: De 32->64->128->256 filtros a 64->128->256->512 filtros
- Justificacion: Modelo necesitaba mas capacidad para patrones complejos
- Ajuste FC: Input de 256*6*6 a 512*6*6

DECISION 3.2: Implementar TTA en test.py y camera.py
- Tecnica: Predecir imagen original + imagen flipeada, promediar
- Implementacion:
  ```python
  def predict_with_tta(model, batch):
      outputs = model(batch)
      flipped = torch.flip(batch, dims=[3])
      outputs_flipped = model(flipped)
      return (outputs + outputs_flipped) / 2
  ```
- Resultado: +1-2% precision sin costo de entrenamiento

RESULTADO: 70.6% precision global (PICO MAXIMO)

PROBLEMA IDENTIFICADO: Overfitting severo
- Train: 94%
- Val: 70%
- Gap: 24% (inaceptable)

------------------------------------------------------------------------------
FASE 4: COMBATE AL OVERFITTING
------------------------------------------------------------------------------

INTENTO 4.1: Reducir Dropout + L2 Regularization (FALLIDO)
- Cambio: Dropout 0.5 -> 0.3, weight_decay=1e-4
- Resultado: 69.5% (PEOR)
- Conclusion: No era la solucion correcta
- Accion: Revertir cambios

DECISION 4.2: Balancear dataset manualmente
- Problema: Usuario agrego ~11k imagenes nuevas causando desbalance extremo
  * ira: 5495 imagenes
  * miedo: 5609 imagenes
  * sorpresa: 5290 imagenes
  * otras clases: ~1500-3000 imagenes
- Error encontrado: Imagenes de diferentes dimensiones
- Fix: Agregar resize en preprocess_image()
  ```python
  if image.shape[:2] != IMG_SIZE:
      image = cv2.resize(image, IMG_SIZE)
  ```
- Solucion: Usuario elimino exceso para balancear a ~3000 por clase

RESULTADO: 69.9% test con mejor distribucion por clase
- sorpresa: +7%
- ira: +4%
- miedo: +3%
- Overfitting persiste: 24% gap

DECISION 4.3: Implementar Mixup Data Augmentation
- Referencia: Papers de FER2013 reportan reduccion de overfitting con Mixup
- Parametros: alpha=0.2 (recomendado para FER)
- Implementacion:
  ```python
  def mixup_data(x, y, alpha=0.2):
      lam = np.random.beta(alpha, alpha)
      batch_size = x.size(0)
      index = torch.randperm(batch_size).to(x.device)
      mixed_x = lam * x + (1 - lam) * x[index, :]
      y_a, y_b = y, y[index]
      return mixed_x, y_a, y_b, lam

  def mixup_criterion(criterion, pred, y_a, y_b, lam):
      return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)
  ```
- Adicionalmente: weight_decay=1e-5 en optimizador

RESULTADO MIXUP: 70.35% test
- Overfitting reducido: 24% -> 19% gap
- Trade-off: Algunas clases bajaron ligeramente (ira -4.6%, miedo -0.8%)
- Beneficio neto: Mejor generalizacion

------------------------------------------------------------------------------
FASE 5: PRUEBAS EN CAMARA REAL (PROBLEMA DE DOMAIN SHIFT)
------------------------------------------------------------------------------

PROBLEMA DETECTADO: camera.py no funciona bien en caras reales
Sintomas reportados por usuario:
- Nunca detecta felicidad/neutralidad
- Solo detecta emociones con gestos MUY exagerados
- Confunde desprecio con asco
- Caras neutras/felices marcadas como tristeza

DIAGNOSTICO: Domain Shift
- FER2013 contiene expresiones ACTUADAS (exageradas, dramaticas)
- Caras reales tienen expresiones SUTILES
- Modelo entrenado en dominio A no funciona en dominio B

INTENTO 5.1: Calibracion post-procesamiento (FALLIDO)
- Implementacion en camera.py:
  * Boost de probabilidad para neutralidad/felicidad cuando tristeza gana
    con baja confianza
  * Temporal smoothing (promedio de ultimas 5 predicciones)
  * Umbral de confianza (<40% = "Incierto")
- Feedback usuario: "no funciono"
- Accion: Revertir todos los cambios en camera.py

DECISION 5.2: Re-entrenar con datos reales
- Datasets recomendados:
  * RAF-DB: Expresiones reales, ~500-800 imagenes por clase
  * CK+ (Cohn-Kanade): Expresiones reales, ~200-300 imagenes por clase

CANTIDADES ESPECIFICAS RECOMENDADAS (basadas en graficas de distribucion):

Para Train/:
- desprecio: 1500 imagenes (compensar minoria severa)
- asco: 1400 imagenes (compensar minoria)
- ira: 800 imagenes (mejorar accuracy)
- miedo: 800 imagenes (mejorar accuracy)
- felicidad: 500 imagenes (ya estaba bien)
- neutralidad: 500 imagenes (ya estaba bien)
- tristeza: 500 imagenes (ya estaba bien)
- sorpresa: 500 imagenes (ya estaba bien)

Para Test/ (30% del Train, SIN overlap):
- desprecio: 450 imagenes
- asco: 420 imagenes
- ira: 240 imagenes
- miedo: 240 imagenes
- felicidad: 150 imagenes
- neutralidad: 150 imagenes
- tristeza: 150 imagenes
- sorpresa: 150 imagenes

DATOS REALMENTE AGREGADOS POR USUARIO (parcial):
RAF-DB:
- sorpresa: Train 505, Test 159
- miedo: Train 281, Test 74
- desprecio: Train 717, Test 160
- ira: Train 705, Test 162
- felicidad: Train 500, Test 150
- neutralidad: Train 500, Test 150
- tristeza: Train 500, Test 153

CK+:
- desprecio: Train 54, Test 0
- asco: Train 177, Test 0
- ira: Train 96, Test 39
- miedo: Train 519, Test 0

RESULTADO FINAL POST-REENTRENAMIENTO: 70.20% test
- Casi igual al anterior (70.35%)
- Clases debiles siguen <60%
- Razon: Test/ sigue dominado por FER2013, no suficientes datos reales

================================================================================
4. ENFOQUES QUE NO FUNCIONARON
================================================================================

4.1 TRANSFER LEARNING CON RESNET-18
- Por que fallo: Domain mismatch fundamental
  * ImageNet: objetos, animales, escenas
  * FER: expresiones faciales humanas
  * Los features aprendidos no son transferibles
- Leccion: Transfer learning no es solucion universal

4.2 FOCAL LOSS
- Por que fallo: Confundio al modelo
- El modelo ya tenia class weights, Focal Loss fue redundante
- Resultado: Precision disminuyo

4.3 WEIGHTED RANDOM SAMPLER
- Por que fallo: Sobrerepresento clases minoritarias
- Efecto: Daño a clases mayoritarias sin beneficio neto
- Mejor alternativa: Class weights en loss function

4.4 AUGMENTATION AGRESIVA PARA MINORIAS
- Por que fallo: Algunas emociones tienen features especificos
- Ejemplo: Sorpresa depende de ojos abiertos, rotacion excesiva lo daña
- Leccion: Augmentation debe ser moderada

4.5 REDUCCION DE DROPOUT + L2
- Por que fallo: Direccion equivocada
- El problema era capacidad excesiva, no regularizacion insuficiente
- Resultado: 69.5% (peor que 70.6%)

4.6 CALIBRACION POST-PROCESAMIENTO EN CAMERA
- Por que fallo: No soluciona el problema de raiz (domain shift)
- Hacks de probabilidad no compensan features mal aprendidos
- La unica solucion real es re-entrenar con datos del dominio objetivo

================================================================================
5. ENFOQUES QUE SI FUNCIONARON
================================================================================

5.1 CLASS WEIGHTS
- Beneficio: +3-5% en clases minoritarias
- Implementacion simple y efectiva
- Formula: peso = total / (num_clases * frecuencia_clase)

5.2 DATA AUGMENTATION MODERADA
- Flip horizontal: Siempre util para caras
- Rotacion leve (+/-15): Simula variacion natural
- Brillo aleatorio: Robustez a iluminacion

5.3 AUMENTO DE CAPACIDAD DEL MODELO
- De 32->64->128->256 a 64->128->256->512 filtros
- Beneficio: +1-2% precision
- Razon: Problema requiere features mas complejos

5.4 TTA (TEST-TIME AUGMENTATION)
- Beneficio: +1-2% sin costo de entrenamiento
- Tecnica: Predecir original + flip, promediar
- Aplica en test.py y camera.py

5.5 MIXUP DATA AUGMENTATION
- Beneficio: Reduccion de overfitting de 24% a 19% gap
- Parametro optimo: alpha=0.2
- Trade-off aceptable: Ligera caida en algunas clases

5.6 BALANCEO DE DATASET
- Beneficio: Distribucion mas uniforme de precision por clase
- Metodo: Agregar datos a clases minoritarias, eliminar exceso de mayoritarias
- Objetivo: ~3000 imagenes por clase en Train

5.7 PREPROCESAMIENTO CLAHE
- Beneficio: Mejora contraste de imagenes
- Especialmente util para iluminacion variable
- Parametros: clipLimit=2.0, tileGridSize=(8,8)

================================================================================
6. REFERENCIAS Y FUENTES
================================================================================

PAPERS CONSULTADOS:
- "Challenges in Representation Learning: A Report on Three Machine Learning
  Contests" (FER2013 original)
- Papers sobre Mixup para regularizacion en clasificacion de imagenes
- Estudios de domain shift en reconocimiento facial

BENCHMARKS CONOCIDOS:
- Precision humana en FER2013: ~65%
- State-of-the-art en FER2013: 73-76%
- Nuestro resultado (70.2%) esta por encima del baseline humano

DATASETS:
- FER2013: https://www.kaggle.com/datasets/msambare/fer2013
- AffectNet: https://www.kaggle.com/datasets/mstjebashazida/affectnet
- RAF-DB: Real-world Affective Faces Database
- CK+: Cohn-Kanade Extended Database

TECNICAS INVESTIGADAS:
- Mixup: Zhang et al., "mixup: Beyond Empirical Risk Minimization"
- Label Smoothing: Szegedy et al., "Rethinking the Inception Architecture"
- Focal Loss: Lin et al., "Focal Loss for Dense Object Detection"

================================================================================
7. ESTADO FINAL DEL PROYECTO
================================================================================

ARQUITECTURA FINAL:
```
EmotionClassifier(
  conv1: Conv2d(1, 64) -> BN -> ReLU -> Conv2d(64, 64) -> BN -> ReLU -> MaxPool -> Dropout(0.25)
  conv2: Conv2d(64, 128) -> BN -> ReLU -> Conv2d(128, 128) -> BN -> ReLU -> MaxPool -> Dropout(0.25)
  conv3: Conv2d(128, 256) -> BN -> ReLU -> Conv2d(256, 256) -> BN -> ReLU -> MaxPool -> Dropout(0.25)
  conv4: Conv2d(256, 512) -> BN -> ReLU -> Conv2d(512, 512) -> BN -> ReLU -> MaxPool -> Dropout(0.25)
  fc: Flatten -> Linear(512*6*6, 512) -> BN -> ReLU -> Dropout(0.5)
      -> Linear(512, 256) -> BN -> ReLU -> Dropout(0.5)
      -> Linear(256, 8)
)
```

TECNICAS ACTIVAS:
- Class Weights: Activado
- Data Augmentation: Flip, rotacion, brillo
- Mixup: alpha=0.2
- TTA: En test.py y camera.py
- Early Stopping: patience=15
- Learning Rate Scheduler: ReduceLROnPlateau

METRICAS FINALES:
- Precision global: 70.20%
- Precision de validacion: 70.86%
- Overfitting gap: ~19% (Train ~90% vs Val ~71%)

PRECISION POR CLASE:
- felicidad: 91.21% (excelente)
- neutralidad: 94.84% (excelente)
- tristeza: 89.69% (excelente)
- desprecio: 67.93% (buena)
- ira: 57.39% (moderada)
- asco: 55.56% (moderada)
- sorpresa: 54.64% (moderada)
- miedo: 51.96% (moderada)

DISTRIBUCION DE DATOS FINAL:
Train: ~24,912 imagenes (~3000 por clase)
Test: ~18,489 imagenes (~2500 por clase)

LIMITACIONES CONOCIDAS:
1. Domain shift: Modelo funciona mejor con expresiones exageradas que sutiles
2. Clases dificiles: asco, miedo, sorpresa siguen por debajo del 60%
3. Camera real: Requiere gestos pronunciados para deteccion confiable

================================================================================
8. CONCLUSIONES Y LECCIONES APRENDIDAS
================================================================================

LOGROS:
1. Mejora de ~65% baseline a 70.2% (+5.2%)
2. Reduccion de overfitting de 24% a 19%
3. Mejor balance entre clases
4. Sistema funcional de deteccion en tiempo real

LECCIONES TECNICAS:
1. Transfer Learning no es solucion universal - evaluar domain match
2. Regularizacion debe ser apropiada al problema (Mixup > Dropout para este caso)
3. Balanceo de datos es crucial para clasificacion multiclase
4. TTA es ganancia "gratis" que siempre debe considerarse
5. Domain shift es problema fundamental que requiere datos del dominio objetivo

LECCIONES DE PROCESO:
1. Documentar cada experimento y resultado
2. Mantener versiones anteriores funcionales antes de cambios mayores
3. Probar en dominio real (camera) temprano en el desarrollo
4. No asumir que mas complejo = mejor (ResNet < CNN custom para este caso)

TRABAJO FUTURO POTENCIAL:
1. Agregar mas datos reales de RAF-DB y CK+ (especialmente en Test/)
2. Explorar arquitecturas especificas para FER (VGGFace, etc.)
3. Implementar deteccion de landmarks faciales como preprocesamiento
4. Fine-tuning especifico para dominio de webcam

================================================================================
FIN DE DOCUMENTACION
================================================================================